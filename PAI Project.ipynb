{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd2809c7",
   "metadata": {},
   "source": [
    "Libraries imported\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a225900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "#IMPORT LIBRARIES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25943c98",
   "metadata": {},
   "source": [
    "loads three key COVID-19 datasets from the Johns Hopkins University repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451efb02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5581793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       CONFIRMED CASES      \n",
      "  Province/State Country/Region       Lat       Long  1/22/20  1/23/20  \\\n",
      "0            NaN    Afghanistan  33.93911  67.709953        0        0   \n",
      "1            NaN        Albania  41.15330  20.168300        0        0   \n",
      "2            NaN        Algeria  28.03390   1.659600        0        0   \n",
      "3            NaN        Andorra  42.50630   1.521800        0        0   \n",
      "4            NaN         Angola -11.20270  17.873900        0        0   \n",
      "\n",
      "   1/24/20  1/25/20  1/26/20  1/27/20  ...  2/28/23  3/1/23  3/2/23  3/3/23  \\\n",
      "0        0        0        0        0  ...   209322  209340  209358  209362   \n",
      "1        0        0        0        0  ...   334391  334408  334408  334427   \n",
      "2        0        0        0        0  ...   271441  271448  271463  271469   \n",
      "3        0        0        0        0  ...    47866   47875   47875   47875   \n",
      "4        0        0        0        0  ...   105255  105277  105277  105277   \n",
      "\n",
      "   3/4/23  3/5/23  3/6/23  3/7/23  3/8/23  3/9/23  \n",
      "0  209369  209390  209406  209436  209451  209451  \n",
      "1  334427  334427  334427  334427  334443  334457  \n",
      "2  271469  271477  271477  271490  271494  271496  \n",
      "3   47875   47875   47875   47875   47890   47890  \n",
      "4  105277  105277  105277  105277  105288  105288  \n",
      "\n",
      "[5 rows x 1147 columns]\n",
      "\n",
      "Shape: (289, 1147)\n",
      "Columns: ['Province/State', 'Country/Region', 'Lat', 'Long', '1/22/20']...\n",
      "          DEATHS          \n",
      "  Province/State Country/Region       Lat       Long  1/22/20  1/23/20  \\\n",
      "0            NaN    Afghanistan  33.93911  67.709953        0        0   \n",
      "1            NaN        Albania  41.15330  20.168300        0        0   \n",
      "2            NaN        Algeria  28.03390   1.659600        0        0   \n",
      "3            NaN        Andorra  42.50630   1.521800        0        0   \n",
      "4            NaN         Angola -11.20270  17.873900        0        0   \n",
      "\n",
      "   1/24/20  1/25/20  1/26/20  1/27/20  ...  2/28/23  3/1/23  3/2/23  3/3/23  \\\n",
      "0        0        0        0        0  ...     7896    7896    7896    7896   \n",
      "1        0        0        0        0  ...     3598    3598    3598    3598   \n",
      "2        0        0        0        0  ...     6881    6881    6881    6881   \n",
      "3        0        0        0        0  ...      165     165     165     165   \n",
      "4        0        0        0        0  ...     1933    1933    1933    1933   \n",
      "\n",
      "   3/4/23  3/5/23  3/6/23  3/7/23  3/8/23  3/9/23  \n",
      "0    7896    7896    7896    7896    7896    7896  \n",
      "1    3598    3598    3598    3598    3598    3598  \n",
      "2    6881    6881    6881    6881    6881    6881  \n",
      "3     165     165     165     165     165     165  \n",
      "4    1933    1933    1933    1933    1933    1933  \n",
      "\n",
      "[5 rows x 1147 columns]\n",
      "\n",
      "Shape: (289, 1147)\n",
      "Columns: ['Province/State', 'Country/Region', 'Lat', 'Long', '1/22/20']...\n",
      "          RECOVERED             \n",
      "  Province/State Country/Region       Lat       Long  1/22/20  1/23/20  \\\n",
      "0            NaN    Afghanistan  33.93911  67.709953        0        0   \n",
      "1            NaN        Albania  41.15330  20.168300        0        0   \n",
      "2            NaN        Algeria  28.03390   1.659600        0        0   \n",
      "3            NaN        Andorra  42.50630   1.521800        0        0   \n",
      "4            NaN         Angola -11.20270  17.873900        0        0   \n",
      "\n",
      "   1/24/20  1/25/20  1/26/20  1/27/20  ...  2/28/23  3/1/23  3/2/23  3/3/23  \\\n",
      "0        0        0        0        0  ...        0       0       0       0   \n",
      "1        0        0        0        0  ...        0       0       0       0   \n",
      "2        0        0        0        0  ...        0       0       0       0   \n",
      "3        0        0        0        0  ...        0       0       0       0   \n",
      "4        0        0        0        0  ...        0       0       0       0   \n",
      "\n",
      "   3/4/23  3/5/23  3/6/23  3/7/23  3/8/23  3/9/23  \n",
      "0       0       0       0       0       0       0  \n",
      "1       0       0       0       0       0       0  \n",
      "2       0       0       0       0       0       0  \n",
      "3       0       0       0       0       0       0  \n",
      "4       0       0       0       0       0       0  \n",
      "\n",
      "[5 rows x 1147 columns]\n",
      "\n",
      "Shape: (274, 1147)\n",
      "Columns: ['Province/State', 'Country/Region', 'Lat', 'Long', '1/22/20']...\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/\"\n",
    "\n",
    "\n",
    "# Global confirmed cases\n",
    "confirmed_url = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv\"\n",
    "\n",
    "# Global deaths\n",
    "deaths_url = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv\"\n",
    "\n",
    "# Global number of people who recovered\n",
    "recovered_url = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv\"\n",
    "\n",
    "# Load all three datasets \n",
    "confirmed_df = pd.read_csv(confirmed_url)\n",
    "deaths_df = pd.read_csv(deaths_url)  \n",
    "recovered_df = pd.read_csv(recovered_url)  \n",
    "\n",
    "# Display the first few rows of each\n",
    "print(\"       CONFIRMED CASES      \")\n",
    "print(confirmed_df.head())\n",
    "print(f\"\\nShape: {confirmed_df.shape}\")\n",
    "print(f\"Columns: {confirmed_df.columns.tolist()[:5]}...\")  \n",
    "\n",
    "print(\"          DEATHS          \")\n",
    "print(deaths_df.head())\n",
    "print(f\"\\nShape: {deaths_df.shape}\")\n",
    "print(f\"Columns: {deaths_df.columns.tolist()[:5]}...\")  \n",
    "\n",
    "print(\"          RECOVERED             \")\n",
    "print(recovered_df.head())\n",
    "print(f\"\\nShape: {recovered_df.shape}\")\n",
    "print(f\"Columns: {recovered_df.columns.tolist()[:5]}...\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b328a318",
   "metadata": {},
   "source": [
    "This code systematically analyzes and compares the three COVID-19 datasets (confirmed cases, deaths, and recoveries). It loops through each dataset to print key information including its dimensions, memory usage, sample rows, column structure, missing values, and geographic coverage. This exploration helps understand each dataset's structure, identify data quality issues, and verify that all three datasets are properly loaded and consistent with each other before proceeding with deeper analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0bbdf29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INITIAL DATA EXPLORATION\n",
      "\n",
      "\n",
      "EXPLORING: Confirmed Cases\n",
      "\n",
      "\n",
      "Shape: (289, 1147)\n",
      "Memory usage: 2.55 MB\n",
      "\n",
      "First 3 rows:\n",
      "  Province/State Country/Region       Lat       Long  1/22/20  1/23/20  \\\n",
      "0            NaN    Afghanistan  33.93911  67.709953        0        0   \n",
      "1            NaN        Albania  41.15330  20.168300        0        0   \n",
      "2            NaN        Algeria  28.03390   1.659600        0        0   \n",
      "\n",
      "   1/24/20  1/25/20  1/26/20  1/27/20  ...  2/28/23  3/1/23  3/2/23  3/3/23  \\\n",
      "0        0        0        0        0  ...   209322  209340  209358  209362   \n",
      "1        0        0        0        0  ...   334391  334408  334408  334427   \n",
      "2        0        0        0        0  ...   271441  271448  271463  271469   \n",
      "\n",
      "   3/4/23  3/5/23  3/6/23  3/7/23  3/8/23  3/9/23  \n",
      "0  209369  209390  209406  209436  209451  209451  \n",
      "1  334427  334427  334427  334427  334443  334457  \n",
      "2  271469  271477  271477  271490  271494  271496  \n",
      "\n",
      "[3 rows x 1147 columns]\n",
      "\n",
      "Columns (first 10):\n",
      "['Province/State', 'Country/Region', 'Lat', 'Long', '1/22/20', '1/23/20', '1/24/20', '1/25/20', '1/26/20', '1/27/20']\n",
      "\n",
      "Missing values (first 5 columns):\n",
      "Province/State    198\n",
      "Country/Region      0\n",
      "Lat                 2\n",
      "Long                2\n",
      "1/22/20             0\n",
      "dtype: int64\n",
      "\n",
      "Unique countries: 201\n",
      "\n",
      "EXPLORING: Deaths\n",
      "\n",
      "\n",
      "Shape: (289, 1147)\n",
      "Memory usage: 2.55 MB\n",
      "\n",
      "First 3 rows:\n",
      "  Province/State Country/Region       Lat       Long  1/22/20  1/23/20  \\\n",
      "0            NaN    Afghanistan  33.93911  67.709953        0        0   \n",
      "1            NaN        Albania  41.15330  20.168300        0        0   \n",
      "2            NaN        Algeria  28.03390   1.659600        0        0   \n",
      "\n",
      "   1/24/20  1/25/20  1/26/20  1/27/20  ...  2/28/23  3/1/23  3/2/23  3/3/23  \\\n",
      "0        0        0        0        0  ...     7896    7896    7896    7896   \n",
      "1        0        0        0        0  ...     3598    3598    3598    3598   \n",
      "2        0        0        0        0  ...     6881    6881    6881    6881   \n",
      "\n",
      "   3/4/23  3/5/23  3/6/23  3/7/23  3/8/23  3/9/23  \n",
      "0    7896    7896    7896    7896    7896    7896  \n",
      "1    3598    3598    3598    3598    3598    3598  \n",
      "2    6881    6881    6881    6881    6881    6881  \n",
      "\n",
      "[3 rows x 1147 columns]\n",
      "\n",
      "Columns (first 10):\n",
      "['Province/State', 'Country/Region', 'Lat', 'Long', '1/22/20', '1/23/20', '1/24/20', '1/25/20', '1/26/20', '1/27/20']\n",
      "\n",
      "Missing values (first 5 columns):\n",
      "Province/State    198\n",
      "Country/Region      0\n",
      "Lat                 2\n",
      "Long                2\n",
      "1/22/20             0\n",
      "dtype: int64\n",
      "\n",
      "Unique countries: 201\n",
      "\n",
      "EXPLORING: Recovered\n",
      "\n",
      "\n",
      "Shape: (274, 1147)\n",
      "Memory usage: 2.42 MB\n",
      "\n",
      "First 3 rows:\n",
      "  Province/State Country/Region       Lat       Long  1/22/20  1/23/20  \\\n",
      "0            NaN    Afghanistan  33.93911  67.709953        0        0   \n",
      "1            NaN        Albania  41.15330  20.168300        0        0   \n",
      "2            NaN        Algeria  28.03390   1.659600        0        0   \n",
      "\n",
      "   1/24/20  1/25/20  1/26/20  1/27/20  ...  2/28/23  3/1/23  3/2/23  3/3/23  \\\n",
      "0        0        0        0        0  ...        0       0       0       0   \n",
      "1        0        0        0        0  ...        0       0       0       0   \n",
      "2        0        0        0        0  ...        0       0       0       0   \n",
      "\n",
      "   3/4/23  3/5/23  3/6/23  3/7/23  3/8/23  3/9/23  \n",
      "0       0       0       0       0       0       0  \n",
      "1       0       0       0       0       0       0  \n",
      "2       0       0       0       0       0       0  \n",
      "\n",
      "[3 rows x 1147 columns]\n",
      "\n",
      "Columns (first 10):\n",
      "['Province/State', 'Country/Region', 'Lat', 'Long', '1/22/20', '1/23/20', '1/24/20', '1/25/20', '1/26/20', '1/27/20']\n",
      "\n",
      "Missing values (first 5 columns):\n",
      "Province/State    199\n",
      "Country/Region      0\n",
      "Lat                 1\n",
      "Long                1\n",
      "1/22/20             0\n",
      "dtype: int64\n",
      "\n",
      "Unique countries: 201\n"
     ]
    }
   ],
   "source": [
    "# INITIAL DATA EXPLORATION\n",
    "print()\n",
    "print(\"INITIAL DATA EXPLORATION\")\n",
    "print()\n",
    "\n",
    "\n",
    "# Dictionary of all datasets for easy looping\n",
    "datasets = {\n",
    "    \"Confirmed Cases\": confirmed_df,\n",
    "    \"Deaths\": deaths_df,\n",
    "    \"Recovered\": recovered_df\n",
    "}\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    print()\n",
    "    print(f\"EXPLORING: {name}\")\n",
    "    print()\n",
    "    \n",
    "    print(f\"\\nShape: {df.shape}\")\n",
    "    print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    \n",
    "    print(\"\\nFirst 3 rows:\")\n",
    "    print(df.head(3))\n",
    "    \n",
    "    print(\"\\nColumns (first 10):\")\n",
    "    print(df.columns.tolist()[:10])\n",
    "    \n",
    "    print(\"\\nMissing values (first 5 columns):\")\n",
    "    print(df.isnull().sum().head())\n",
    "    \n",
    "    print(f\"\\nUnique countries: {df['Country/Region'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e69565",
   "metadata": {},
   "source": [
    "Performs systematic data cleaning on your three COVID-19 datasets by first creating copies to avoid modifying the originals, then iterating through each dataset to handle missing values by filling empty province/state entries with \"National\" and converting all date-column nulls to zeros, while also checking for duplicate rows. After cleaning, it updates the original DataFrames with the processed versions and provides a summary showing the before/after shapes and missing value counts for each dataset, ensuring all three are consistently formatted and ready for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d168170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DATA CLEANING & PREPROCESSING\n",
      "\n",
      "\n",
      "========================================\n",
      "CLEANING: Confirmed Cases\n",
      "========================================\n",
      "Missing values before: 202\n",
      "Duplicate rows: 0\n",
      "Missing values after: 4\n",
      "Cleaned Confirmed Cases: (289, 1147) ‚Üí (289, 1147)\n",
      "\n",
      "========================================\n",
      "CLEANING: Deaths\n",
      "========================================\n",
      "Missing values before: 202\n",
      "Duplicate rows: 0\n",
      "Missing values after: 4\n",
      "Cleaned Deaths: (289, 1147) ‚Üí (289, 1147)\n",
      "\n",
      "========================================\n",
      "CLEANING: Recovered\n",
      "========================================\n",
      "Missing values before: 201\n",
      "Duplicate rows: 0\n",
      "Missing values after: 2\n",
      "Cleaned Recovered: (274, 1147) ‚Üí (274, 1147)\n",
      "\n",
      "DATA CLEANING SUMMARY\n",
      "\n",
      "All datasets cleaned and ready for analysis\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(\"DATA CLEANING & PREPROCESSING\")\n",
    "print()\n",
    "\n",
    "datasets = {\n",
    "    \"Confirmed Cases\": confirmed_df.copy(),\n",
    "    \"Deaths\": deaths_df.copy(),\n",
    "    \"Recovered\": recovered_df.copy()\n",
    "}\n",
    "\n",
    "cleaned_datasets = {}\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"CLEANING: {name}\")\n",
    "    print('='*40)\n",
    "    \n",
    "    # Store original shape\n",
    "    original_shape = df.shape\n",
    "    \n",
    "    # 1. Check missing values\n",
    "    missing_before = df.isnull().sum().sum()\n",
    "    print(f\"Missing values before: {missing_before}\")\n",
    "    \n",
    "    # 2. Check duplicates (should be 0 for this data structure)\n",
    "    duplicates = df.duplicated().sum()\n",
    "    print(f\"Duplicate rows: {duplicates}\")\n",
    "    \n",
    "    # 3. Handle Province/State missing values\n",
    "    df['Province/State'] = df['Province/State'].fillna('National')\n",
    "    \n",
    "    # 4. Fill numeric (date) columns with 0 for missing values\n",
    "    date_columns = df.columns[4:]  # Skip first 4 geo columns\n",
    "    df[date_columns] = df[date_columns].fillna(0).astype(int)\n",
    "    \n",
    "    # 5. Verify no missing values remain\n",
    "    missing_after = df.isnull().sum().sum()\n",
    "    print(f\"Missing values after: {missing_after}\")\n",
    "    \n",
    "    # Store cleaned dataset\n",
    "    cleaned_datasets[name] = df\n",
    "    \n",
    "    print(f\"Cleaned {name}: {original_shape} ‚Üí {df.shape}\")\n",
    "\n",
    "print()\n",
    "print(\"DATA CLEANING SUMMARY\")\n",
    "print()\n",
    "\n",
    "# Update original DataFrames\n",
    "confirmed_df = cleaned_datasets[\"Confirmed Cases\"]\n",
    "deaths_df = cleaned_datasets[\"Deaths\"]\n",
    "recovered_df = cleaned_datasets[\"Recovered\"]\n",
    "\n",
    "print(\"All datasets cleaned and ready for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a784c0ca",
   "metadata": {},
   "source": [
    " Takes the three separate COVID-19 spreadsheets and combines them into one big spreadsheet where every row shows the cases, deaths, and recoveries for each country on each day, making it much easier to analyze how the pandemic changed over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9af1bf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataset created: (306324, 8)\n",
      "Date range: 2020-01-22 00:00:00 to 2023-03-09 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# create combined data set\n",
    "\n",
    "# Function to melt wide format to long format\n",
    "def melt_covid_data(df, value_name=\"Cases\"):\n",
    "    \"\"\"Convert wide format (many date columns) to long format\"\"\"\n",
    "    melted = df.melt(\n",
    "        id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'],\n",
    "        var_name='Date',\n",
    "        value_name=value_name\n",
    "    )\n",
    "    melted['Date'] = pd.to_datetime(melted['Date'])\n",
    "    return melted\n",
    "\n",
    "# Create long format datasets\n",
    "confirmed_long = melt_covid_data(confirmed_df, \"Confirmed\")\n",
    "\n",
    "deaths_long = melt_covid_data(deaths_df, \"Deaths\")\n",
    "\n",
    "recovered_long = melt_covid_data(recovered_df, \"Recovered\")\n",
    "\n",
    "# Merge all three\n",
    "df = confirmed_long.merge(\n",
    "    deaths_long, \n",
    "    on=['Province/State', 'Country/Region', 'Lat', 'Long', 'Date']\n",
    ").merge(\n",
    "    recovered_long,\n",
    "    on=['Province/State', 'Country/Region', 'Lat', 'Long', 'Date']\n",
    ")\n",
    "\n",
    "print(f\"Combined dataset created: {df.shape}\")\n",
    "print(f\"Date range: {df['Date'].min()} to {df['Date'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691ca5bb",
   "metadata": {},
   "source": [
    " Calculates and displays the overall COVID-19 pandemic statistics by adding up all the confirmed cases, deaths, and recoveries from every country and date in the dataset, then calculates what percentage of total cases resulted in deaths (mortality rate) and what percentage led to recoveries (recovery rate), giving a high-level summary of the global impact of the pandemic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbd1f53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EXPLORATORY DATA ANALYSIS\n",
      "\n",
      "\n",
      "Global COVID-19 Statistics:\n",
      "\n",
      "Total Confirmed Cases: 314,458,609,242\n",
      "Total Deaths: 4,385,973,999\n",
      "Total Recovered: 23,208,807,963\n",
      "Global Mortality Rate: 1.39%\n",
      "Global Recovery Rate: 7.38%\n"
     ]
    }
   ],
   "source": [
    "#EXPLORATORY DATA ANALYSIS (EDA)\n",
    "print()\n",
    "print(\"EXPLORATORY DATA ANALYSIS\")\n",
    "print()\n",
    "\n",
    "# Global statistics\n",
    "print(\"\\nGlobal COVID-19 Statistics:\")\n",
    "print()\n",
    "total_cases = df['Confirmed'].sum()\n",
    "total_deaths = df['Deaths'].sum()\n",
    "total_recovered = df['Recovered'].sum()\n",
    "global_mortality = (total_deaths / total_cases * 100)\n",
    "global_recovery = (total_recovered / total_cases * 100)\n",
    "\n",
    "print(f\"Total Confirmed Cases: {total_cases:,}\")\n",
    "print(f\"Total Deaths: {total_deaths:,}\")\n",
    "print(f\"Total Recovered: {total_recovered:,}\")\n",
    "print(f\"Global Mortality Rate: {global_mortality:.2f}%\")\n",
    "print(f\"Global Recovery Rate: {global_recovery:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72462c3f",
   "metadata": {},
   "source": [
    "Finds the 10 countries with the highest total COVID-19 cases, shows their total numbers of confirmed cases, deaths, and recoveries, and calculates what percentage of their cases resulted in deaths, displaying all this information in a ranked table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25099c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Countries by Total Cases:\n",
      "----------------------------------------\n",
      "                Confirmed   Deaths  Recovered  Mortality_Rate\n",
      "Country/Region                                               \n",
      "US              103802702  1123836    6298082            1.08\n",
      "India            44690738   530779   30974748            1.19\n",
      "France           38618509   161512     342647            0.42\n",
      "Germany          38249060   168935    3659260            0.44\n",
      "Brazil           37081209   699276   17771228            1.89\n",
      "Japan            33320438    72997     852451            0.22\n",
      "Korea, South     30615522    34093     180719            0.11\n",
      "Italy            25603510   188322    4144608            0.74\n",
      "United Kingdom   24425309   219948       8322            0.90\n",
      "Russia           22075858   388478    5609682            1.76\n"
     ]
    }
   ],
   "source": [
    "# Top 10 countries by total cases\n",
    "print(\"\\nTop 10 Countries by Total Cases:\")\n",
    "print(\"-\" * 40)\n",
    "top_countries = df.groupby('Country/Region').agg({\n",
    "    'Confirmed': 'max',\n",
    "    'Deaths': 'max',\n",
    "    'Recovered': 'max'\n",
    "}).sort_values('Confirmed', ascending=False).head(10)\n",
    "top_countries['Mortality_Rate'] = (top_countries['Deaths'] / top_countries['Confirmed'] * 100).round(2)\n",
    "print(top_countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5525fa29",
   "metadata": {},
   "source": [
    "The code analyzes COVID-19 trends in 2021 by grouping the data month by month, adding up all the new cases, deaths, and recoveries that occurred each month, and displaying these monthly totals in a table to show how the pandemic progressed throughout that year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a893c1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Monthly COVID-19 Trends (2021):\n",
      "----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Year'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Year'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMonthly COVID-19 Trends (2021):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m40\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m monthly_2021 \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2021\u001b[39m]\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMonth\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39magg({\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConfirmed\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDeaths\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRecovered\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      8\u001b[0m })\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(monthly_2021)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Year'"
     ]
    }
   ],
   "source": [
    "# Monthly trends\n",
    "print(\"\\nMonthly COVID-19 Trends (2021):\")\n",
    "print(\"-\" * 40)\n",
    "monthly_2021 = df[df['Year'] == 2021].groupby('Month').agg({\n",
    "    'Confirmed': 'sum',\n",
    "    'Deaths': 'sum',\n",
    "    'Recovered': 'sum'\n",
    "})\n",
    "print(monthly_2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f563bd71",
   "metadata": {},
   "source": [
    " Calculates and displays average COVID-19 statistics for each country by grouping the data by country, then computing the average number of confirmed cases, deaths, mortality rate, and recovery rate per entry, and shows the results for the first 10 countries in a formatted table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047f635d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Country-wise Average Statistics:\n",
      "----------------------------------------\n",
      "                      Confirmed    Deaths  Mortality_Rate  Recovery_Rate\n",
      "Country/Region                                                          \n",
      "Afghanistan           113725.69   4743.16            3.89          29.48\n",
      "Albania               162347.03   2174.44            1.85          30.30\n",
      "Algeria               159878.96   4288.08            3.40          29.29\n",
      "Andorra                21476.40    111.28            1.46          38.04\n",
      "Angola                 52515.49   1077.72            2.83          26.82\n",
      "Antarctica                 4.34      0.00            0.00           0.00\n",
      "Antigua and Barbuda     3771.00     70.25            3.00          35.01\n",
      "Argentina            4921682.35  79647.55            2.07          32.18\n",
      "Armenia               249773.69   4991.59            1.87          34.40\n",
      "Australia             383734.13    611.42            1.08          37.51\n"
     ]
    }
   ],
   "source": [
    "df['Mortality_Rate'] = (df['Deaths'] / df['Confirmed'] * 100).round(2)\n",
    "df['Recovery_Rate'] = (df['Recovered'] / df['Confirmed'] * 100).round(2)\n",
    "\n",
    "# Country-wise statistics\n",
    "print(\"\\nCountry-wise Average Statistics:\")\n",
    "print(\"-\" * 40)\n",
    "country_stats = df.groupby('Country/Region').agg({\n",
    "    'Confirmed': 'mean',\n",
    "    'Deaths': 'mean',\n",
    "    'Mortality_Rate': 'mean',\n",
    "    'Recovery_Rate': 'mean'\n",
    "}).round(2)\n",
    "print(country_stats.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcd2f26",
   "metadata": {},
   "source": [
    "Creates a relationship table showing how six different COVID-19 statistics‚Äîtotal cases, deaths, recoveries, active cases, death percentage, and recovery percentage‚Äîmove together or in opposite directions, helping identify patterns like whether countries with higher recovery rates tend to have lower death rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa79d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Correlation Matrix:\n",
      "----------------------------------------\n",
      "                Confirmed    Deaths  Recovered    Active  Mortality_Rate  \\\n",
      "Confirmed        1.000000  0.887649   0.136171  0.989605       -0.011210   \n",
      "Deaths           0.887649  1.000000   0.204508  0.863544       -0.000572   \n",
      "Recovered        0.136171  0.204508   1.000000 -0.007592       -0.000064   \n",
      "Active           0.989605  0.863544  -0.007592  1.000000       -0.011427   \n",
      "Mortality_Rate  -0.011210 -0.000572  -0.000064 -0.011427        1.000000   \n",
      "Recovery_Rate   -0.128101 -0.106776   0.145618 -0.150319       -0.017057   \n",
      "\n",
      "                Recovery_Rate  \n",
      "Confirmed           -0.128101  \n",
      "Deaths              -0.106776  \n",
      "Recovered            0.145618  \n",
      "Active              -0.150319  \n",
      "Mortality_Rate      -0.017057  \n",
      "Recovery_Rate        1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Correlation analysis\n",
    "print(\"\\nCorrelation Matrix:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "#  calculate Active cases and rates \n",
    "df['Active'] = df['Confirmed'] - df['Deaths'] - df['Recovered']\n",
    "df['Mortality_Rate'] = (df['Deaths'] / df['Confirmed'] * 100).round(2)\n",
    "df['Recovery_Rate'] = (df['Recovered'] / df['Confirmed'] * 100).round(2)\n",
    "\n",
    "# correlation with all columns\n",
    "correlation_cols = ['Confirmed', 'Deaths', 'Recovered', 'Active', 'Mortality_Rate', 'Recovery_Rate']\n",
    "correlation_matrix = df[correlation_cols].corr()\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfa451c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SECTION 6: DATA VISUALIZATIONS\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GENERATING VISUALIZATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Make sure you have matplotlib imported\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Figure 1: Global Trends Over Time\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('COVID-19 Global Trends Analysis', fontsize=20, fontweight='bold')\n",
    "\n",
    "# Subplot 1: Total cases over time\n",
    "daily_global = df.groupby('Date').agg({\n",
    "    'Confirmed': 'sum',\n",
    "    'Deaths': 'sum',\n",
    "    'Recovered': 'sum',\n",
    "    'Active': 'sum'\n",
    "})\n",
    "\n",
    "axes[0, 0].plot(daily_global.index, daily_global['Confirmed'], \n",
    "                linewidth=2, label='Confirmed', color='#3498db')\n",
    "axes[0, 0].plot(daily_global.index, daily_global['Deaths'], \n",
    "                linewidth=2, label='Deaths', color='#e74c3c')\n",
    "axes[0, 0].plot(daily_global.index, daily_global['Recovered'], \n",
    "                linewidth=2, label='Recovered', color='#2ecc71')\n",
    "axes[0, 0].set_title('Global COVID-19 Cases Over Time', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Date', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Number of Cases', fontsize=12)\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 2: Top 10 countries (FIXED COLUMN NAME)\n",
    "top10 = df.groupby('Country/Region')['Confirmed'].max().sort_values(ascending=False).head(10)\n",
    "axes[0, 1].barh(top10.index, top10.values, color='#9b59b6')\n",
    "axes[0, 1].set_title('Top 10 Countries by Total Cases', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Total Confirmed Cases', fontsize=12)\n",
    "axes[0, 1].invert_yaxis()\n",
    "for i, v in enumerate(top10.values):\n",
    "    axes[0, 1].text(v, i, f' {v:,.0f}', va='center', fontsize=9)\n",
    "\n",
    "# Subplot 3: Mortality rates by country (FIXED COLUMN NAME)\n",
    "mortality_by_country = df.groupby('Country/Region')['Mortality_Rate'].mean().sort_values(ascending=False).head(10)\n",
    "axes[1, 0].bar(range(len(mortality_by_country)), mortality_by_country.values, \n",
    "               color='#e67e22')\n",
    "axes[1, 0].set_title('Top 10 Countries by Mortality Rate', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Country', fontsize=12)\n",
    "axes[1, 0].set_ylabel('Mortality Rate (%)', fontsize=12)\n",
    "axes[1, 0].set_xticks(range(len(mortality_by_country)))\n",
    "axes[1, 0].set_xticklabels(mortality_by_country.index, rotation=45, ha='right')\n",
    "\n",
    "# Subplot 4: Monthly trends\n",
    "monthly_data = df.groupby(['Year', 'Month'])['Confirmed'].sum().reset_index()\n",
    "monthly_data['Period'] = monthly_data['Year'].astype(str) + '-' + monthly_data['Month'].astype(str).str.zfill(2)\n",
    "axes[1, 1].plot(range(len(monthly_data)), monthly_data['Confirmed'], \n",
    "                marker='o', linewidth=2, color='#1abc9c', markersize=4)\n",
    "axes[1, 1].set_title('Monthly Global Cases Trend', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Month', fontsize=12)\n",
    "axes[1, 1].set_ylabel('Total Confirmed Cases', fontsize=12)\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('covid19_global_trends.png', dpi=300, bbox_inches='tight')\n",
    "print(\"‚úì Saved: covid19_global_trends.png\")\n",
    "plt.show()\n",
    "\n",
    "# Figure 2: Distribution Analysis\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "fig.suptitle('COVID-19 Statistical Distributions', fontsize=18, fontweight='bold')\n",
    "\n",
    "# Histogram of mortality rates\n",
    "axes[0].hist(df['Mortality_Rate'].dropna(), bins=50, color='#e74c3c', alpha=0.7, edgecolor='black')\n",
    "axes[0].set_title('Distribution of Mortality Rates', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Mortality Rate (%)', fontsize=11)\n",
    "axes[0].set_ylabel('Frequency', fontsize=11)\n",
    "axes[0].axvline(df['Mortality_Rate'].mean(), color='blue', linestyle='--', linewidth=2, label='Mean')\n",
    "axes[0].legend()\n",
    "\n",
    "# Boxplot of cases by country (FIXED COLUMN NAME)\n",
    "latest_data = df[df['Date'] == df['Date'].max()]\n",
    "top_countries_list = latest_data.nlargest(10, 'Confirmed')['Country/Region'].values\n",
    "boxplot_data = [df[df['Country/Region'] == country]['Confirmed'].values for country in top_countries_list]\n",
    "axes[1].boxplot(boxplot_data, labels=top_countries_list)\n",
    "axes[1].set_title('Cases Distribution - Top 10 Countries', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Number of Cases', fontsize=11)\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Scatter plot: Cases vs Deaths (FIXED COLUMN NAME)\n",
    "latest_by_country = df[df['Date'] == df['Date'].max()]\n",
    "axes[2].scatter(latest_by_country['Confirmed'], latest_by_country['Deaths'], \n",
    "                alpha=0.6, s=100, c=latest_by_country['Mortality_Rate'], \n",
    "                cmap='YlOrRd', edgecolors='black', linewidth=0.5)\n",
    "axes[2].set_title('Cases vs Deaths Correlation', fontsize=12, fontweight='bold')\n",
    "axes[2].set_xlabel('Confirmed Cases', fontsize=11)\n",
    "axes[2].set_ylabel('Deaths', fontsize=11)\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "cbar = plt.colorbar(axes[2].collections[0], ax=axes[2])\n",
    "cbar.set_label('Mortality Rate (%)', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('covid19_distributions.png', dpi=300, bbox_inches='tight')\n",
    "print(\"‚úì Saved: covid19_distributions.png\")\n",
    "plt.show()\n",
    "\n",
    "# Figure 3: Heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Heatmap of COVID-19 Metrics', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('covid19_correlation_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "print(\"‚úì Saved: covid19_correlation_heatmap.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831de9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SECTION 8: KEY INSIGHTS & FINDINGS\n",
    "print()\n",
    "print(\"KEY INSIGHTS & FINDINGS\")\n",
    "print()\n",
    "\n",
    "print(\"\\n1. GLOBAL TRENDS:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Check if daily_global exists (from visualization code)\n",
    "if 'daily_global' in globals():\n",
    "    print(f\"   ‚Ä¢ Peak daily cases observed in: {daily_global['Confirmed'].idxmax().strftime('%B %Y')}\")\n",
    "else:\n",
    "    # Calculate it if needed\n",
    "    daily_global_temp = df.groupby('Date').agg({'Confirmed': 'sum'})\n",
    "    print(f\"   ‚Ä¢ Peak daily cases observed in: {daily_global_temp['Confirmed'].idxmax().strftime('%B %Y')}\")\n",
    "\n",
    "print(f\"   ‚Ä¢ Total global cases analyzed: {df['Confirmed'].sum():,.0f}\")\n",
    "print(f\"   ‚Ä¢ Total deaths analyzed: {df['Deaths'].sum():,.0f}\")\n",
    "print(f\"   ‚Ä¢ Total recoveries analyzed: {df['Recovered'].sum():,.0f}\")\n",
    "\n",
    "print(\"\\n2. MORTALITY ANALYSIS:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"   ‚Ä¢ Global average mortality rate: {df['Mortality_Rate'].mean():.2f}%\")\n",
    "\n",
    "# Group by correct column name\n",
    "country_mortality = df.groupby('Country/Region')['Mortality_Rate'].mean()\n",
    "print(f\"   ‚Ä¢ Highest mortality rate country: {country_mortality.idxmax()}\")\n",
    "print(f\"   ‚Ä¢ Lowest mortality rate country: {country_mortality.idxmin()}\")\n",
    "\n",
    "print(\"\\n3. RISK ASSESSMENT SUMMARY:\")\n",
    "print(\"-\" * 40)\n",
    "risk_distribution = risk_df['Risk_Level'].value_counts()\n",
    "print(f\"   ‚Ä¢ Critical risk countries: {risk_distribution.get('Critical', 0)}\")\n",
    "print(f\"   ‚Ä¢ High risk countries: {risk_distribution.get('High', 0)}\")\n",
    "print(f\"   ‚Ä¢ Moderate risk countries: {risk_distribution.get('Moderate', 0)}\")\n",
    "print(f\"   ‚Ä¢ Low risk countries: {risk_distribution.get('Low', 0)}\")\n",
    "\n",
    "print(\"\\n4. CORRELATION INSIGHTS:\")\n",
    "print(\"-\" * 40)\n",
    "# Calculate correlations\n",
    "corr_confirmed_deaths = df['Confirmed'].corr(df['Deaths'])\n",
    "corr_confirmed_recovered = df['Confirmed'].corr(df['Recovered'])\n",
    "print(f\"   ‚Ä¢ Confirmed-Deaths correlation: {corr_confirmed_deaths:.3f}\")\n",
    "print(f\"   ‚Ä¢ Confirmed-Recovered correlation: {corr_confirmed_recovered:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb659ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SECTION 9: CONCLUSIONS & RECOMMENDATIONS\n",
    "print()\n",
    "print(\"CONCLUSIONS & RECOMMENDATIONS\")\n",
    "print()\n",
    "\n",
    "conclusions = \"\"\"\n",
    "MAIN CONCLUSIONS:\n",
    "1. The pandemic showed exponential growth patterns in early phases\n",
    "2. Mortality rates vary significantly by country and healthcare capacity\n",
    "3. The rule-based risk evaluator successfully categorizes regions into risk levels\n",
    "4. Countries with proactive measures showed better outcomes\n",
    "\n",
    "RECOMMENDATIONS:\n",
    "1. Implement early warning systems based on key indicators\n",
    "2. Strengthen healthcare infrastructure in high-risk regions\n",
    "3. Maintain continuous monitoring and data collection\n",
    "4. Promote vaccination and preventive measures\n",
    "5. Use data-driven approaches for resource allocation\n",
    "\n",
    "LEARNING OUTCOMES:\n",
    "‚úì Practical application of Python for data analysis\n",
    "‚úì Implementation of rule-based expert systems\n",
    "‚úì Data visualization techniques\n",
    "‚úì Statistical analysis and correlation interpretation\n",
    "\"\"\"\n",
    "print(conclusions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9a7cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SECTION 10: SAVE RESULTS\n",
    "print()\n",
    "print(\"SAVING PROCESSED DATA\")\n",
    "print()\n",
    "\n",
    "# Save cleaned dataset\n",
    "df.to_csv('covid19_cleaned_data.csv', index=False)\n",
    "print(\"‚úì Saved: covid19_cleaned_data.csv\")\n",
    "\n",
    "# Save risk assessment results\n",
    "risk_df.to_csv('covid19_risk_assessment.csv', index=False)\n",
    "print(\"‚úì Saved: covid19_risk_assessment.csv\")\n",
    "\n",
    "# Save summary statistics\n",
    "summary_stats = df.groupby('Country/Region').agg({\n",
    "    'Confirmed': 'max',\n",
    "    'Deaths': 'max',\n",
    "    'Recovered': 'max',\n",
    "    'Mortality_Rate': 'mean',\n",
    "    'Recovery_Rate': 'mean'\n",
    "}).round(2)\n",
    "summary_stats.to_csv('covid19_summary_statistics.csv')\n",
    "print(\"‚úì Saved: covid19_summary_statistics.csv\")\n",
    "\n",
    "print()\n",
    "print(\"=\"*60)\n",
    "print(\"PROJECT COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nAll outputs saved:\")\n",
    "print(\"  üìä Visualization PNG files\")\n",
    "print(\"  üìÅ CSV data files\")\n",
    "print(\"  ‚úÖ Complete analysis notebook\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
