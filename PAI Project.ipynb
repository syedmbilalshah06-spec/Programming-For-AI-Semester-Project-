{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd2809c7",
   "metadata": {},
   "source": [
    "Libraries imported\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a225900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "#IMPORT LIBRARIES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25943c98",
   "metadata": {},
   "source": [
    "loads three key COVID-19 datasets from the Johns Hopkins University repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5581793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       CONFIRMED CASES      \n",
      "  Province/State Country/Region       Lat       Long  1/22/20  1/23/20  \\\n",
      "0            NaN    Afghanistan  33.93911  67.709953        0        0   \n",
      "1            NaN        Albania  41.15330  20.168300        0        0   \n",
      "2            NaN        Algeria  28.03390   1.659600        0        0   \n",
      "3            NaN        Andorra  42.50630   1.521800        0        0   \n",
      "4            NaN         Angola -11.20270  17.873900        0        0   \n",
      "\n",
      "   1/24/20  1/25/20  1/26/20  1/27/20  ...  2/28/23  3/1/23  3/2/23  3/3/23  \\\n",
      "0        0        0        0        0  ...   209322  209340  209358  209362   \n",
      "1        0        0        0        0  ...   334391  334408  334408  334427   \n",
      "2        0        0        0        0  ...   271441  271448  271463  271469   \n",
      "3        0        0        0        0  ...    47866   47875   47875   47875   \n",
      "4        0        0        0        0  ...   105255  105277  105277  105277   \n",
      "\n",
      "   3/4/23  3/5/23  3/6/23  3/7/23  3/8/23  3/9/23  \n",
      "0  209369  209390  209406  209436  209451  209451  \n",
      "1  334427  334427  334427  334427  334443  334457  \n",
      "2  271469  271477  271477  271490  271494  271496  \n",
      "3   47875   47875   47875   47875   47890   47890  \n",
      "4  105277  105277  105277  105277  105288  105288  \n",
      "\n",
      "[5 rows x 1147 columns]\n",
      "\n",
      "Shape: (289, 1147)\n",
      "Columns: ['Province/State', 'Country/Region', 'Lat', 'Long', '1/22/20']...\n",
      "          DEATHS          \n",
      "  Province/State Country/Region       Lat       Long  1/22/20  1/23/20  \\\n",
      "0            NaN    Afghanistan  33.93911  67.709953        0        0   \n",
      "1            NaN        Albania  41.15330  20.168300        0        0   \n",
      "2            NaN        Algeria  28.03390   1.659600        0        0   \n",
      "3            NaN        Andorra  42.50630   1.521800        0        0   \n",
      "4            NaN         Angola -11.20270  17.873900        0        0   \n",
      "\n",
      "   1/24/20  1/25/20  1/26/20  1/27/20  ...  2/28/23  3/1/23  3/2/23  3/3/23  \\\n",
      "0        0        0        0        0  ...     7896    7896    7896    7896   \n",
      "1        0        0        0        0  ...     3598    3598    3598    3598   \n",
      "2        0        0        0        0  ...     6881    6881    6881    6881   \n",
      "3        0        0        0        0  ...      165     165     165     165   \n",
      "4        0        0        0        0  ...     1933    1933    1933    1933   \n",
      "\n",
      "   3/4/23  3/5/23  3/6/23  3/7/23  3/8/23  3/9/23  \n",
      "0    7896    7896    7896    7896    7896    7896  \n",
      "1    3598    3598    3598    3598    3598    3598  \n",
      "2    6881    6881    6881    6881    6881    6881  \n",
      "3     165     165     165     165     165     165  \n",
      "4    1933    1933    1933    1933    1933    1933  \n",
      "\n",
      "[5 rows x 1147 columns]\n",
      "\n",
      "Shape: (289, 1147)\n",
      "Columns: ['Province/State', 'Country/Region', 'Lat', 'Long', '1/22/20']...\n",
      "          RECOVERED             \n",
      "  Province/State Country/Region       Lat       Long  1/22/20  1/23/20  \\\n",
      "0            NaN    Afghanistan  33.93911  67.709953        0        0   \n",
      "1            NaN        Albania  41.15330  20.168300        0        0   \n",
      "2            NaN        Algeria  28.03390   1.659600        0        0   \n",
      "3            NaN        Andorra  42.50630   1.521800        0        0   \n",
      "4            NaN         Angola -11.20270  17.873900        0        0   \n",
      "\n",
      "   1/24/20  1/25/20  1/26/20  1/27/20  ...  2/28/23  3/1/23  3/2/23  3/3/23  \\\n",
      "0        0        0        0        0  ...        0       0       0       0   \n",
      "1        0        0        0        0  ...        0       0       0       0   \n",
      "2        0        0        0        0  ...        0       0       0       0   \n",
      "3        0        0        0        0  ...        0       0       0       0   \n",
      "4        0        0        0        0  ...        0       0       0       0   \n",
      "\n",
      "   3/4/23  3/5/23  3/6/23  3/7/23  3/8/23  3/9/23  \n",
      "0       0       0       0       0       0       0  \n",
      "1       0       0       0       0       0       0  \n",
      "2       0       0       0       0       0       0  \n",
      "3       0       0       0       0       0       0  \n",
      "4       0       0       0       0       0       0  \n",
      "\n",
      "[5 rows x 1147 columns]\n",
      "\n",
      "Shape: (274, 1147)\n",
      "Columns: ['Province/State', 'Country/Region', 'Lat', 'Long', '1/22/20']...\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/\"\n",
    "\n",
    "\n",
    "# Global confirmed cases\n",
    "confirmed_url = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv\"\n",
    "\n",
    "# Global deaths\n",
    "deaths_url = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv\"\n",
    "\n",
    "# Global number of people who recovered\n",
    "recovered_url = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv\"\n",
    "\n",
    "# Load all three datasets \n",
    "confirmed_df = pd.read_csv(confirmed_url)\n",
    "deaths_df = pd.read_csv(deaths_url)  \n",
    "recovered_df = pd.read_csv(recovered_url)  \n",
    "\n",
    "# Display the first few rows of each\n",
    "print(\"       CONFIRMED CASES      \")\n",
    "print(confirmed_df.head())\n",
    "print(f\"\\nShape: {confirmed_df.shape}\")\n",
    "print(f\"Columns: {confirmed_df.columns.tolist()[:5]}...\")  \n",
    "\n",
    "print(\"          DEATHS          \")\n",
    "print(deaths_df.head())\n",
    "print(f\"\\nShape: {deaths_df.shape}\")\n",
    "print(f\"Columns: {deaths_df.columns.tolist()[:5]}...\")  \n",
    "\n",
    "print(\"          RECOVERED             \")\n",
    "print(recovered_df.head())\n",
    "print(f\"\\nShape: {recovered_df.shape}\")\n",
    "print(f\"Columns: {recovered_df.columns.tolist()[:5]}...\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b328a318",
   "metadata": {},
   "source": [
    "This code systematically analyzes and compares the three COVID-19 datasets (confirmed cases, deaths, and recoveries). It loops through each dataset to print key information including its dimensions, memory usage, sample rows, column structure, missing values, and geographic coverage. This exploration helps understand each dataset's structure, identify data quality issues, and verify that all three datasets are properly loaded and consistent with each other before proceeding with deeper analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0bbdf29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INITIAL DATA EXPLORATION\n",
      "\n",
      "\n",
      "EXPLORING: Confirmed Cases\n",
      "\n",
      "\n",
      "Shape: (289, 1147)\n",
      "Memory usage: 2.55 MB\n",
      "\n",
      "First 3 rows:\n",
      "  Province/State Country/Region       Lat       Long  1/22/20  1/23/20  \\\n",
      "0            NaN    Afghanistan  33.93911  67.709953        0        0   \n",
      "1            NaN        Albania  41.15330  20.168300        0        0   \n",
      "2            NaN        Algeria  28.03390   1.659600        0        0   \n",
      "\n",
      "   1/24/20  1/25/20  1/26/20  1/27/20  ...  2/28/23  3/1/23  3/2/23  3/3/23  \\\n",
      "0        0        0        0        0  ...   209322  209340  209358  209362   \n",
      "1        0        0        0        0  ...   334391  334408  334408  334427   \n",
      "2        0        0        0        0  ...   271441  271448  271463  271469   \n",
      "\n",
      "   3/4/23  3/5/23  3/6/23  3/7/23  3/8/23  3/9/23  \n",
      "0  209369  209390  209406  209436  209451  209451  \n",
      "1  334427  334427  334427  334427  334443  334457  \n",
      "2  271469  271477  271477  271490  271494  271496  \n",
      "\n",
      "[3 rows x 1147 columns]\n",
      "\n",
      "Columns (first 10):\n",
      "['Province/State', 'Country/Region', 'Lat', 'Long', '1/22/20', '1/23/20', '1/24/20', '1/25/20', '1/26/20', '1/27/20']\n",
      "\n",
      "Missing values (first 5 columns):\n",
      "Province/State    198\n",
      "Country/Region      0\n",
      "Lat                 2\n",
      "Long                2\n",
      "1/22/20             0\n",
      "dtype: int64\n",
      "\n",
      "Unique countries: 201\n",
      "\n",
      "EXPLORING: Deaths\n",
      "\n",
      "\n",
      "Shape: (289, 1147)\n",
      "Memory usage: 2.55 MB\n",
      "\n",
      "First 3 rows:\n",
      "  Province/State Country/Region       Lat       Long  1/22/20  1/23/20  \\\n",
      "0            NaN    Afghanistan  33.93911  67.709953        0        0   \n",
      "1            NaN        Albania  41.15330  20.168300        0        0   \n",
      "2            NaN        Algeria  28.03390   1.659600        0        0   \n",
      "\n",
      "   1/24/20  1/25/20  1/26/20  1/27/20  ...  2/28/23  3/1/23  3/2/23  3/3/23  \\\n",
      "0        0        0        0        0  ...     7896    7896    7896    7896   \n",
      "1        0        0        0        0  ...     3598    3598    3598    3598   \n",
      "2        0        0        0        0  ...     6881    6881    6881    6881   \n",
      "\n",
      "   3/4/23  3/5/23  3/6/23  3/7/23  3/8/23  3/9/23  \n",
      "0    7896    7896    7896    7896    7896    7896  \n",
      "1    3598    3598    3598    3598    3598    3598  \n",
      "2    6881    6881    6881    6881    6881    6881  \n",
      "\n",
      "[3 rows x 1147 columns]\n",
      "\n",
      "Columns (first 10):\n",
      "['Province/State', 'Country/Region', 'Lat', 'Long', '1/22/20', '1/23/20', '1/24/20', '1/25/20', '1/26/20', '1/27/20']\n",
      "\n",
      "Missing values (first 5 columns):\n",
      "Province/State    198\n",
      "Country/Region      0\n",
      "Lat                 2\n",
      "Long                2\n",
      "1/22/20             0\n",
      "dtype: int64\n",
      "\n",
      "Unique countries: 201\n",
      "\n",
      "EXPLORING: Recovered\n",
      "\n",
      "\n",
      "Shape: (274, 1147)\n",
      "Memory usage: 2.42 MB\n",
      "\n",
      "First 3 rows:\n",
      "  Province/State Country/Region       Lat       Long  1/22/20  1/23/20  \\\n",
      "0            NaN    Afghanistan  33.93911  67.709953        0        0   \n",
      "1            NaN        Albania  41.15330  20.168300        0        0   \n",
      "2            NaN        Algeria  28.03390   1.659600        0        0   \n",
      "\n",
      "   1/24/20  1/25/20  1/26/20  1/27/20  ...  2/28/23  3/1/23  3/2/23  3/3/23  \\\n",
      "0        0        0        0        0  ...        0       0       0       0   \n",
      "1        0        0        0        0  ...        0       0       0       0   \n",
      "2        0        0        0        0  ...        0       0       0       0   \n",
      "\n",
      "   3/4/23  3/5/23  3/6/23  3/7/23  3/8/23  3/9/23  \n",
      "0       0       0       0       0       0       0  \n",
      "1       0       0       0       0       0       0  \n",
      "2       0       0       0       0       0       0  \n",
      "\n",
      "[3 rows x 1147 columns]\n",
      "\n",
      "Columns (first 10):\n",
      "['Province/State', 'Country/Region', 'Lat', 'Long', '1/22/20', '1/23/20', '1/24/20', '1/25/20', '1/26/20', '1/27/20']\n",
      "\n",
      "Missing values (first 5 columns):\n",
      "Province/State    199\n",
      "Country/Region      0\n",
      "Lat                 1\n",
      "Long                1\n",
      "1/22/20             0\n",
      "dtype: int64\n",
      "\n",
      "Unique countries: 201\n"
     ]
    }
   ],
   "source": [
    "# INITIAL DATA EXPLORATION\n",
    "print()\n",
    "print(\"INITIAL DATA EXPLORATION\")\n",
    "print()\n",
    "\n",
    "\n",
    "# Dictionary of all datasets for easy looping\n",
    "datasets = {\n",
    "    \"Confirmed Cases\": confirmed_df,\n",
    "    \"Deaths\": deaths_df,\n",
    "    \"Recovered\": recovered_df\n",
    "}\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    print()\n",
    "    print(f\"EXPLORING: {name}\")\n",
    "    print()\n",
    "    \n",
    "    print(f\"\\nShape: {df.shape}\")\n",
    "    print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    \n",
    "    print(\"\\nFirst 3 rows:\")\n",
    "    print(df.head(3))\n",
    "    \n",
    "    print(\"\\nColumns (first 10):\")\n",
    "    print(df.columns.tolist()[:10])\n",
    "    \n",
    "    print(\"\\nMissing values (first 5 columns):\")\n",
    "    print(df.isnull().sum().head())\n",
    "    \n",
    "    print(f\"\\nUnique countries: {df['Country/Region'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e69565",
   "metadata": {},
   "source": [
    "Performs systematic data cleaning on your three COVID-19 datasets by first creating copies to avoid modifying the originals, then iterating through each dataset to handle missing values by filling empty province/state entries with \"National\" and converting all date-column nulls to zeros, while also checking for duplicate rows. After cleaning, it updates the original DataFrames with the processed versions and provides a summary showing the before/after shapes and missing value counts for each dataset, ensuring all three are consistently formatted and ready for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d168170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DATA CLEANING & PREPROCESSING\n",
      "\n",
      "\n",
      "========================================\n",
      "CLEANING: Confirmed Cases\n",
      "========================================\n",
      "Missing values before: 202\n",
      "Duplicate rows: 0\n",
      "Missing values after: 4\n",
      "Cleaned Confirmed Cases: (289, 1147) → (289, 1147)\n",
      "\n",
      "========================================\n",
      "CLEANING: Deaths\n",
      "========================================\n",
      "Missing values before: 202\n",
      "Duplicate rows: 0\n",
      "Missing values after: 4\n",
      "Cleaned Deaths: (289, 1147) → (289, 1147)\n",
      "\n",
      "========================================\n",
      "CLEANING: Recovered\n",
      "========================================\n",
      "Missing values before: 201\n",
      "Duplicate rows: 0\n",
      "Missing values after: 2\n",
      "Cleaned Recovered: (274, 1147) → (274, 1147)\n",
      "\n",
      "DATA CLEANING SUMMARY\n",
      "\n",
      "All datasets cleaned and ready for analysis\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(\"DATA CLEANING & PREPROCESSING\")\n",
    "print()\n",
    "\n",
    "datasets = {\n",
    "    \"Confirmed Cases\": confirmed_df.copy(),\n",
    "    \"Deaths\": deaths_df.copy(),\n",
    "    \"Recovered\": recovered_df.copy()\n",
    "}\n",
    "\n",
    "cleaned_datasets = {}\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"CLEANING: {name}\")\n",
    "    print('='*40)\n",
    "    \n",
    "    # Store original shape\n",
    "    original_shape = df.shape\n",
    "    \n",
    "    # 1. Check missing values\n",
    "    missing_before = df.isnull().sum().sum()\n",
    "    print(f\"Missing values before: {missing_before}\")\n",
    "    \n",
    "    # 2. Check duplicates (should be 0 for this data structure)\n",
    "    duplicates = df.duplicated().sum()\n",
    "    print(f\"Duplicate rows: {duplicates}\")\n",
    "    \n",
    "    # 3. Handle Province/State missing values\n",
    "    df['Province/State'] = df['Province/State'].fillna('National')\n",
    "    \n",
    "    # 4. Fill numeric (date) columns with 0 for missing values\n",
    "    date_columns = df.columns[4:]  # Skip first 4 geo columns\n",
    "    df[date_columns] = df[date_columns].fillna(0).astype(int)\n",
    "    \n",
    "    # 5. Verify no missing values remain\n",
    "    missing_after = df.isnull().sum().sum()\n",
    "    print(f\"Missing values after: {missing_after}\")\n",
    "    \n",
    "    # Store cleaned dataset\n",
    "    cleaned_datasets[name] = df\n",
    "    \n",
    "    print(f\"Cleaned {name}: {original_shape} → {df.shape}\")\n",
    "\n",
    "print()\n",
    "print(\"DATA CLEANING SUMMARY\")\n",
    "print()\n",
    "\n",
    "# Update original DataFrames\n",
    "confirmed_df = cleaned_datasets[\"Confirmed Cases\"]\n",
    "deaths_df = cleaned_datasets[\"Deaths\"]\n",
    "recovered_df = cleaned_datasets[\"Recovered\"]\n",
    "\n",
    "print(\"All datasets cleaned and ready for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a784c0ca",
   "metadata": {},
   "source": [
    " Takes the three separate COVID-19 spreadsheets and combines them into one big spreadsheet where every row shows the cases, deaths, and recoveries for each country on each day, making it much easier to analyze how the pandemic changed over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9af1bf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataset created: (306324, 8)\n",
      "Date range: 2020-01-22 00:00:00 to 2023-03-09 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# create combined data set\n",
    "\n",
    "# Function to melt wide format to long format\n",
    "def melt_covid_data(df, value_name=\"Cases\"):\n",
    "    \"\"\"Convert wide format (many date columns) to long format\"\"\"\n",
    "    melted = df.melt(\n",
    "        id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'],\n",
    "        var_name='Date',\n",
    "        value_name=value_name\n",
    "    )\n",
    "    melted['Date'] = pd.to_datetime(melted['Date'])\n",
    "    return melted\n",
    "\n",
    "# Create long format datasets\n",
    "confirmed_long = melt_covid_data(confirmed_df, \"Confirmed\")\n",
    "\n",
    "deaths_long = melt_covid_data(deaths_df, \"Deaths\")\n",
    "\n",
    "recovered_long = melt_covid_data(recovered_df, \"Recovered\")\n",
    "\n",
    "# Merge all three\n",
    "df = confirmed_long.merge(\n",
    "    deaths_long, \n",
    "    on=['Province/State', 'Country/Region', 'Lat', 'Long', 'Date']\n",
    ").merge(\n",
    "    recovered_long,\n",
    "    on=['Province/State', 'Country/Region', 'Lat', 'Long', 'Date']\n",
    ")\n",
    "\n",
    "print(f\"Combined dataset created: {df.shape}\")\n",
    "print(f\"Date range: {df['Date'].min()} to {df['Date'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691ca5bb",
   "metadata": {},
   "source": [
    " Calculates and displays the overall COVID-19 pandemic statistics by adding up all the confirmed cases, deaths, and recoveries from every country and date in the dataset, then calculates what percentage of total cases resulted in deaths (mortality rate) and what percentage led to recoveries (recovery rate), giving a high-level summary of the global impact of the pandemic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbd1f53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EXPLORATORY DATA ANALYSIS\n",
      "\n",
      "\n",
      "Global COVID-19 Statistics:\n",
      "\n",
      "Total Confirmed Cases: 314,458,609,242\n",
      "Total Deaths: 4,385,973,999\n",
      "Total Recovered: 23,208,807,963\n",
      "Global Mortality Rate: 1.39%\n",
      "Global Recovery Rate: 7.38%\n"
     ]
    }
   ],
   "source": [
    "#EXPLORATORY DATA ANALYSIS (EDA)\n",
    "print()\n",
    "print(\"EXPLORATORY DATA ANALYSIS\")\n",
    "print()\n",
    "\n",
    "# Global statistics\n",
    "print(\"\\nGlobal COVID-19 Statistics:\")\n",
    "print()\n",
    "total_cases = df['Confirmed'].sum()\n",
    "total_deaths = df['Deaths'].sum()\n",
    "total_recovered = df['Recovered'].sum()\n",
    "global_mortality = (total_deaths / total_cases * 100)\n",
    "global_recovery = (total_recovered / total_cases * 100)\n",
    "\n",
    "print(f\"Total Confirmed Cases: {total_cases:,}\")\n",
    "print(f\"Total Deaths: {total_deaths:,}\")\n",
    "print(f\"Total Recovered: {total_recovered:,}\")\n",
    "print(f\"Global Mortality Rate: {global_mortality:.2f}%\")\n",
    "print(f\"Global Recovery Rate: {global_recovery:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72462c3f",
   "metadata": {},
   "source": [
    "Finds the 10 countries with the highest total COVID-19 cases, shows their total numbers of confirmed cases, deaths, and recoveries, and calculates what percentage of their cases resulted in deaths, displaying all this information in a ranked table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25099c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Countries by Total Cases:\n",
      "----------------------------------------\n",
      "                Confirmed   Deaths  Recovered  Mortality_Rate\n",
      "Country/Region                                               \n",
      "US              103802702  1123836    6298082            1.08\n",
      "India            44690738   530779   30974748            1.19\n",
      "France           38618509   161512     342647            0.42\n",
      "Germany          38249060   168935    3659260            0.44\n",
      "Brazil           37081209   699276   17771228            1.89\n",
      "Japan            33320438    72997     852451            0.22\n",
      "Korea, South     30615522    34093     180719            0.11\n",
      "Italy            25603510   188322    4144608            0.74\n",
      "United Kingdom   24425309   219948       8322            0.90\n",
      "Russia           22075858   388478    5609682            1.76\n"
     ]
    }
   ],
   "source": [
    "# Top 10 countries by total cases\n",
    "print(\"\\nTop 10 Countries by Total Cases:\")\n",
    "print(\"-\" * 40)\n",
    "top_countries = df.groupby('Country/Region').agg({\n",
    "    'Confirmed': 'max',\n",
    "    'Deaths': 'max',\n",
    "    'Recovered': 'max'\n",
    "}).sort_values('Confirmed', ascending=False).head(10)\n",
    "top_countries['Mortality_Rate'] = (top_countries['Deaths'] / top_countries['Confirmed'] * 100).round(2)\n",
    "print(top_countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5525fa29",
   "metadata": {},
   "source": [
    "The code analyzes COVID-19 trends in 2021 by grouping the data month by month, adding up all the new cases, deaths, and recoveries that occurred each month, and displaying these monthly totals in a table to show how the pandemic progressed throughout that year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a893c1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly trends\n",
    "print(\"\\nMonthly COVID-19 Trends (2021):\")\n",
    "print(\"-\" * 40)\n",
    "monthly_2021 = df[df['Year'] == 2021].groupby('Month').agg({\n",
    "    'Confirmed': 'sum',\n",
    "    'Deaths': 'sum',\n",
    "    'Recovered': 'sum'\n",
    "})\n",
    "print(monthly_2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f563bd71",
   "metadata": {},
   "source": [
    " Calculates and displays average COVID-19 statistics for each country by grouping the data by country, then computing the average number of confirmed cases, deaths, mortality rate, and recovery rate per entry, and shows the results for the first 10 countries in a formatted table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "047f635d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Country-wise Average Statistics:\n",
      "----------------------------------------\n",
      "                      Confirmed    Deaths  Mortality_Rate  Recovery_Rate\n",
      "Country/Region                                                          \n",
      "Afghanistan           113725.69   4743.16            3.89          29.48\n",
      "Albania               162347.03   2174.44            1.85          30.30\n",
      "Algeria               159878.96   4288.08            3.40          29.29\n",
      "Andorra                21476.40    111.28            1.46          38.04\n",
      "Angola                 52515.49   1077.72            2.83          26.82\n",
      "Antarctica                 4.34      0.00            0.00           0.00\n",
      "Antigua and Barbuda     3771.00     70.25            3.00          35.01\n",
      "Argentina            4921682.35  79647.55            2.07          32.18\n",
      "Armenia               249773.69   4991.59            1.87          34.40\n",
      "Australia             383734.13    611.42            1.08          37.51\n"
     ]
    }
   ],
   "source": [
    "df['Mortality_Rate'] = (df['Deaths'] / df['Confirmed'] * 100).round(2)\n",
    "df['Recovery_Rate'] = (df['Recovered'] / df['Confirmed'] * 100).round(2)\n",
    "\n",
    "# Country-wise statistics\n",
    "print(\"\\nCountry-wise Average Statistics:\")\n",
    "print(\"-\" * 40)\n",
    "country_stats = df.groupby('Country/Region').agg({\n",
    "    'Confirmed': 'mean',\n",
    "    'Deaths': 'mean',\n",
    "    'Mortality_Rate': 'mean',\n",
    "    'Recovery_Rate': 'mean'\n",
    "}).round(2)\n",
    "print(country_stats.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
